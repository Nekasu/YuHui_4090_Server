{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用Dataset类构建训练集\n",
    "train_data = datasets.MNIST(\"./MNIST_dataset\", train=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5], std=[0.5])]), download=True)\n",
    "\n",
    "# 利用Dataset类构建测试集b\n",
    "test_data = datasets.MNIST(\"./MNIST_dataset\", train=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5], std=[0.5])]), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# 测试数据集的可用性\n",
    "\n",
    "img, label = train_data[4]\n",
    "img = img.numpy().transpose(1, 2, 0)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 变量定义\n",
    "\n",
    "batch_size = 256\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "writer = SummaryWriter(\"MNIST_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络搭建\n",
    "class MNIST_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 20, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(80, 20),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(64, 20),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(20, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# 用于处理feature的hook函数\n",
    "class HookTool:\n",
    "    def __init__(self):\n",
    "        self.fea = None\n",
    "\n",
    "    def hook_fun(self, module, fea_in, fea_out):\n",
    "        '''\n",
    "        注意用于处理feature的hook函数必须包含三个参数[module, fea_in, fea_out]，参数的名字可以自己起，但其意义是\n",
    "        固定的，第一个参数表示torch里的一个子module，比如Linear,Conv2d等，第二个参数是该module的输入，其类型是\n",
    "        tuple；第三个参数是该module的输出，其类型是tensor。注意输入和输出的类型是不一样的，切记。\n",
    "        '''\n",
    "        self.fea = fea_out\n",
    "\n",
    "def get_feas_by_hook(model):\n",
    "    \"\"\"\n",
    "    提取Conv2d后的feature，我们需要遍历模型的module，然后找到Conv2d，把hook函数注册到这个module上；\n",
    "    这就相当于告诉模型，我要在Conv2d这一层，用hook_fun处理该层输出的feature.\n",
    "    由于一个模型中可能有多个Conv2d，所以我们要用hook_feas存储下来每一个Conv2d后的feature\n",
    "    \"\"\"\n",
    "    fea_hooks = []\n",
    "    for n, m in model.named_modules():\n",
    "        if isinstance(m, torch.nn.MaxPool2d):\n",
    "            cur_hook = HookTool()\n",
    "            m.register_forward_hook(cur_hook.hook_fun)\n",
    "            fea_hooks.append(cur_hook)\n",
    "\n",
    "    return fea_hooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_net(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "    (10): Linear(in_features=80, out_features=20, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=20, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "The number of hooks is: 3\n",
      "The shape of the 1 Conv2d feature is: torch.Size([256, 6, 14, 14])\n",
      "The shape of the 2 Conv2d feature is: torch.Size([256, 16, 7, 7])\n",
      "The shape of the 3 Conv2d feature is: torch.Size([256, 20, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "net = MNIST_net()\n",
    "print(net)\n",
    "x = torch.randn([256, 1, 28, 28])\n",
    "fea_hooks = get_feas_by_hook(net)\n",
    "out = net(x)\n",
    "print('The number of hooks is:', len(fea_hooks))\n",
    "for i in range(len(fea_hooks)):\n",
    "    print(f'The shape of the {i+1} Conv2d feature is:', fea_hooks[i].fea.shape)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if(torch.cuda.is_available()):\n",
    "    net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------第1轮训练开始------------\n",
      "第100/234步训练： Loss:0.29208171367645264 时间：7.46974515914917\n",
      "第200/234步训练： Loss:0.14860495924949646 时间：11.537485122680664\n",
      "第1轮训练平均损失:0.5890215635299683\n",
      "整体测试集损失为:6.3175554275512695\n",
      "整体测试集正确率为:0.9462999701499939\n",
      "-------------第2轮训练开始------------\n",
      "第100/234步训练： Loss:0.16363349556922913 时间：17.832884311676025\n",
      "第200/234步训练： Loss:0.05160970985889435 时间：21.375827074050903\n",
      "第2轮训练平均损失:0.12562799453735352\n",
      "整体测试集损失为:3.640005588531494\n",
      "整体测试集正确率为:0.9682999849319458\n",
      "-------------第3轮训练开始------------\n",
      "第100/234步训练： Loss:0.05372177064418793 时间：27.485269784927368\n",
      "第200/234步训练： Loss:0.07710392773151398 时间：30.69276785850525\n",
      "第3轮训练平均损失:0.08513591438531876\n",
      "整体测试集损失为:2.400620222091675\n",
      "整体测试集正确率为:0.9787999987602234\n",
      "-------------第4轮训练开始------------\n",
      "第100/234步训练： Loss:0.08975907415151596 时间：36.60400104522705\n",
      "第200/234步训练： Loss:0.09290478378534317 时间：40.47622060775757\n",
      "第4轮训练平均损失:0.0672721341252327\n",
      "整体测试集损失为:2.555290937423706\n",
      "整体测试集正确率为:0.9769999980926514\n",
      "-------------第5轮训练开始------------\n",
      "第100/234步训练： Loss:0.05998261645436287 时间：46.055946826934814\n",
      "第200/234步训练： Loss:0.0725407525897026 时间：49.33144736289978\n",
      "第5轮训练平均损失:0.05735359340906143\n",
      "整体测试集损失为:2.1874947547912598\n",
      "整体测试集正确率为:0.9809999465942383\n",
      "-------------第6轮训练开始------------\n",
      "第100/234步训练： Loss:0.06796939671039581 时间：55.17874240875244\n",
      "第200/234步训练： Loss:0.06359262764453888 时间：58.60847091674805\n",
      "第6轮训练平均损失:0.04980258271098137\n",
      "整体测试集损失为:1.697780728340149\n",
      "整体测试集正确率为:0.9842999577522278\n",
      "-------------第7轮训练开始------------\n",
      "第100/234步训练： Loss:0.027433371171355247 时间：65.74787306785583\n",
      "第200/234步训练： Loss:0.038407307118177414 时间：69.08114647865295\n",
      "第7轮训练平均损失:0.04247833788394928\n",
      "整体测试集损失为:1.6532843112945557\n",
      "整体测试集正确率为:0.9838999509811401\n",
      "-------------第8轮训练开始------------\n",
      "第100/234步训练： Loss:0.05611225217580795 时间：74.87186527252197\n",
      "第200/234步训练： Loss:0.04531316086649895 时间：78.35295867919922\n",
      "第8轮训练平均损失:0.04006977751851082\n",
      "整体测试集损失为:1.7282830476760864\n",
      "整体测试集正确率为:0.984499990940094\n",
      "-------------第9轮训练开始------------\n",
      "第100/234步训练： Loss:0.02479185350239277 时间：83.82116889953613\n",
      "第200/234步训练： Loss:0.03361321985721588 时间：87.28455924987793\n",
      "第9轮训练平均损失:0.03589615970849991\n",
      "整体测试集损失为:1.666527509689331\n",
      "整体测试集正确率为:0.9842000007629395\n",
      "-------------第10轮训练开始------------\n",
      "第100/234步训练： Loss:0.028530854731798172 时间：92.74390959739685\n",
      "第200/234步训练： Loss:0.053675439208745956 时间：95.93077278137207\n",
      "第10轮训练平均损失:0.03440927341580391\n",
      "整体测试集损失为:1.4511568546295166\n",
      "整体测试集正确率为:0.986299991607666\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.002\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "epoch = 10\n",
    "total_train_step = 0\n",
    "total_test_step = 0\n",
    "step = 0\n",
    "start_time = time.time()\n",
    "for i in range(epoch):\n",
    "    print(f\"-------------第{i + 1}轮训练开始------------\")\n",
    "    total_running_loss = 0\n",
    "    step = 0\n",
    "    for data in train_dataloader:\n",
    "        imgs, labels = data\n",
    "        if (torch.cuda.is_available()):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "        output = net(imgs)\n",
    "        loss = loss_fn(output, labels)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_train_step += 1\n",
    "        step += 1\n",
    "        total_running_loss += loss\n",
    "        if step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(f\"第{step}/{train_data_size // batch_size}步训练： Loss:{loss} 时间：{end_time - start_time}\")\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "    print(f\"第{i + 1}轮训练平均损失:{total_running_loss / (train_data_size / batch_size)}\")\n",
    "    total_test_loss = 0\n",
    "    total_correct_num = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            imgs, labels = data\n",
    "            if (torch.cuda.is_available()):\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "            output = net(imgs)\n",
    "            loss = loss_fn(output, labels)\n",
    "            total_test_loss += loss\n",
    "            total_correct_num += (output.argmax(1) == labels).sum()\n",
    "\n",
    "\n",
    "    total_accuracy = total_correct_num / test_data_size\n",
    "    print(f\"整体测试集损失为:{total_test_loss}\")\n",
    "    print(f\"整体测试集正确率为:{total_accuracy}\")\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy, total_test_step)\n",
    "    total_test_step += 1\n",
    "\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[](./MNIST_dataset/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zxt_cuda_11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
